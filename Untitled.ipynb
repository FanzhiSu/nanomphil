{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= np.loadtxt('beta_mean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.37807681, 1.37547478, 1.37393279, 1.36312317, 1.37651263,\n",
       "       1.37480787, 1.37450751, 1.37517025, 1.3833713 , 1.37441263,\n",
       "       1.38562917, 1.37755262, 1.37405159, 1.37365787, 1.37874754,\n",
       "       1.38003295, 1.37425503, 1.37291132, 1.38692632, 1.3789372 ,\n",
       "       1.38345861, 1.38455001, 1.37424745, 1.38415174, 1.38288892,\n",
       "       1.37669589, 1.38954658, 1.37696181, 1.36783112, 1.37376292,\n",
       "       1.37045255, 1.36774026, 1.38333886, 1.36530018, 1.37938247,\n",
       "       1.36694412, 1.37810334, 1.37367585, 1.36867543, 1.37385144,\n",
       "       1.37522564, 1.37564095, 1.37033632, 1.37658319, 1.37249116,\n",
       "       1.38445167, 1.378358  , 1.37982626, 1.37266822, 1.36958549,\n",
       "       1.37615511, 1.36980424, 1.38326941, 1.37075175, 1.3697383 ,\n",
       "       1.38200871, 1.37206488, 1.37320718, 1.37967645, 1.38083733,\n",
       "       1.38416827, 1.37654183, 1.38061847, 1.37695061, 1.38450233,\n",
       "       1.37967081, 1.37649304, 1.37395786, 1.37257783, 1.37625814,\n",
       "       1.3841477 , 1.36945057, 1.3730696 , 1.36863548, 1.37746133,\n",
       "       1.37512901, 1.37634763, 1.37510366, 1.36885522, 1.38890777,\n",
       "       1.36717559, 1.36775891, 1.37232721, 1.37653587, 1.36964921,\n",
       "       1.37723564, 1.38465115, 1.38335197, 1.36932131, 1.36920265,\n",
       "       1.37727006, 1.38552468, 1.37671435, 1.3716618 , 1.37236723,\n",
       "       1.37436233, 1.36930566, 1.37948052, 1.36905524, 1.38747209,\n",
       "       1.38338162, 1.37437977, 1.38564637, 1.38053412, 1.37552159,\n",
       "       1.37868339, 1.39250813, 1.37047303, 1.36781792, 1.37649914,\n",
       "       1.37293317, 1.3783833 , 1.37434018, 1.36954536, 1.37719789,\n",
       "       1.37281847, 1.37654533, 1.37453562, 1.37883173, 1.37945118,\n",
       "       1.37160639, 1.38873282, 1.37534367, 1.37975336, 1.36439679,\n",
       "       1.37427515, 1.38033257, 1.37481889, 1.38004764, 1.37798241,\n",
       "       1.3792529 , 1.37281998, 1.37693127, 1.37542082, 1.36642982,\n",
       "       1.3693617 , 1.37835905, 1.38932088, 1.37037538, 1.37920147,\n",
       "       1.37118674, 1.3959737 , 1.36839357, 1.38159133, 1.37613004,\n",
       "       1.37480008, 1.37003499, 1.37495393, 1.37528901, 1.37167941,\n",
       "       1.37519   , 1.37597928, 1.37712239, 1.36222184, 1.37243743,\n",
       "       1.36899021, 1.37784978, 1.36822958, 1.38839774, 1.38354378,\n",
       "       1.37511355, 1.37442952, 1.3751795 , 1.37259619, 1.36706301,\n",
       "       1.37109209, 1.3789319 , 1.37145093, 1.38312955, 1.36430208,\n",
       "       1.38315507, 1.3698019 , 1.3792049 , 1.36825171, 1.38249294,\n",
       "       1.37509897, 1.38722355, 1.379178  , 1.37034843, 1.37851842,\n",
       "       1.38126439, 1.37193494, 1.37106087, 1.36747065, 1.37837275,\n",
       "       1.37843062, 1.37231113, 1.36485426, 1.37222722, 1.37364473,\n",
       "       1.3808989 , 1.37041887, 1.36714743, 1.37804895, 1.3838712 ,\n",
       "       1.37549019, 1.37773648, 1.38502674, 1.37524396, 1.37553532,\n",
       "       1.36842014, 1.37566756, 1.37889144, 1.37811232, 1.380396  ,\n",
       "       1.37932128, 1.37403186, 1.38092899, 1.37699541, 1.37240989,\n",
       "       1.38296831, 1.38356227, 1.37366116, 1.38314723, 1.37531254,\n",
       "       1.3794576 , 1.37101488, 1.38173905, 1.37813009, 1.37389732,\n",
       "       1.37124438, 1.37021182, 1.37076352, 1.36840188, 1.37046048,\n",
       "       1.37405293, 1.37684264, 1.38085545, 1.37349132, 1.38297547,\n",
       "       1.38159707, 1.3807166 , 1.38478201, 1.37869164, 1.38456258,\n",
       "       1.37578979, 1.3707221 , 1.37826152, 1.36968303, 1.37355749,\n",
       "       1.37229428, 1.37208972, 1.37771004, 1.374959  , 1.37568551,\n",
       "       1.37365551, 1.37092777, 1.37977589, 1.37482644, 1.36897458,\n",
       "       1.38046206, 1.36858179, 1.36967292, 1.37388928, 1.37616478,\n",
       "       1.37238034, 1.3786939 , 1.38024806, 1.36849057, 1.37699162,\n",
       "       1.37822937, 1.38290818, 1.37532569, 1.37944479, 1.3750985 ,\n",
       "       1.36659665, 1.3609741 , 1.38559427, 1.37596381, 1.38132827,\n",
       "       1.38204343, 1.37280373, 1.36928482, 1.38517389, 1.37336125,\n",
       "       1.37942007, 1.37424296, 1.37269952, 1.36899406, 1.37683529,\n",
       "       1.3747747 , 1.37344944, 1.37945548, 1.37526724, 1.3724607 ,\n",
       "       1.38252223, 1.37573223, 1.37248547, 1.36494421, 1.37930758,\n",
       "       1.36718067, 1.37442625, 1.3803252 , 1.37144304, 1.37212611,\n",
       "       1.38638902, 1.37951577, 1.37418402, 1.38108978, 1.37155542,\n",
       "       1.37181763, 1.3785098 , 1.36595006, 1.37170205, 1.37131627,\n",
       "       1.38322956, 1.388803  , 1.36706323, 1.36013083, 1.36814675,\n",
       "       1.38336942, 1.37207028, 1.36610707, 1.36307832, 1.3660481 ,\n",
       "       1.38788298, 1.36639269, 1.37976806, 1.37524087, 1.38601148,\n",
       "       1.37549842, 1.38547977, 1.37426816, 1.38538455, 1.38353793,\n",
       "       1.36996757, 1.38253645, 1.36847962, 1.37399542, 1.37447782,\n",
       "       1.37526786, 1.37337738, 1.38388261, 1.3707218 , 1.37552765,\n",
       "       1.38177828, 1.37127223, 1.38075081, 1.37701037, 1.3753511 ,\n",
       "       1.36531147, 1.36770319, 1.37836918, 1.3805136 , 1.3623894 ,\n",
       "       1.38621984, 1.37346156, 1.38189221, 1.3744149 , 1.37822355,\n",
       "       1.37111412, 1.38544879, 1.374262  , 1.36730139, 1.37642123,\n",
       "       1.3641975 , 1.37455336, 1.37600799, 1.36976608, 1.3765137 ,\n",
       "       1.38106315, 1.37698822, 1.38456552, 1.37311454, 1.36859791,\n",
       "       1.36733071, 1.38102942, 1.37017921, 1.37661062, 1.37507509,\n",
       "       1.37960029, 1.37151449, 1.37861825, 1.38792006, 1.37097046,\n",
       "       1.37587047, 1.36770423, 1.37563417, 1.37225456, 1.37123205,\n",
       "       1.36422692, 1.38626422, 1.36953011, 1.3784213 , 1.37174627,\n",
       "       1.37759549, 1.36253924, 1.37549334, 1.3823166 , 1.3771147 ,\n",
       "       1.37841525, 1.37622445, 1.37384507, 1.37451599, 1.37817262,\n",
       "       1.38055294, 1.39068635, 1.37827744, 1.37663793, 1.36955584,\n",
       "       1.37392224, 1.36360992, 1.37043993, 1.3675641 , 1.38396075,\n",
       "       1.3729096 , 1.37023172, 1.3751436 , 1.36731402, 1.37703755,\n",
       "       1.37483315, 1.37896689, 1.37225342, 1.3792641 , 1.38112605,\n",
       "       1.37483704, 1.36794864, 1.3725112 , 1.37739446, 1.36460925,\n",
       "       1.37776611, 1.37962023, 1.37275513, 1.38131787, 1.37896793,\n",
       "       1.36874259, 1.37996406, 1.37643345, 1.37387239, 1.37082396,\n",
       "       1.37364587, 1.38514474, 1.37639572, 1.38382595, 1.36907295,\n",
       "       1.36784233, 1.36677757, 1.37401738, 1.37311148, 1.37931493,\n",
       "       1.37922485, 1.37817241, 1.37866099, 1.37468611, 1.3778162 ,\n",
       "       1.39170936, 1.36217735, 1.37307651, 1.36654201, 1.37025783,\n",
       "       1.38471284, 1.36648043, 1.3716734 , 1.38529175, 1.3753121 ,\n",
       "       1.37936956, 1.37198223, 1.38231447, 1.36696345, 1.3786171 ,\n",
       "       1.37884923, 1.37406994, 1.38195114, 1.37641853, 1.37886632,\n",
       "       1.38013402, 1.3756746 , 1.37555532, 1.36722487, 1.36683202,\n",
       "       1.373248  , 1.37231874, 1.36858511, 1.37889538, 1.38031007,\n",
       "       1.38109995, 1.36932154, 1.37775599, 1.36525648, 1.3781637 ,\n",
       "       1.38546648, 1.37206737, 1.38142777, 1.37938873, 1.37175775,\n",
       "       1.38355349, 1.37454514, 1.3857705 , 1.3733124 , 1.37087038,\n",
       "       1.38463259, 1.37772128, 1.37162493, 1.38994501, 1.38152954,\n",
       "       1.37156399, 1.38100053, 1.37487381, 1.37519284, 1.37833091,\n",
       "       1.3728693 , 1.37245618, 1.36878987, 1.37717918, 1.38268383,\n",
       "       1.3872621 , 1.37050917, 1.37269217, 1.37283608, 1.3703827 ,\n",
       "       1.37582279, 1.36736839, 1.38155349, 1.37284456, 1.36920993,\n",
       "       1.37496476, 1.38224441, 1.37355308, 1.36464918, 1.36771286,\n",
       "       1.37126808, 1.37590501, 1.38093066, 1.38128622, 1.3723697 ,\n",
       "       1.37483581, 1.37373711, 1.37058883, 1.37441056, 1.37028594,\n",
       "       1.37337107, 1.37676916, 1.372249  , 1.38033996, 1.37031473,\n",
       "       1.37324142, 1.36999256, 1.38650351, 1.37167784, 1.38314358,\n",
       "       1.37340335, 1.36415033, 1.37519573, 1.37905527, 1.36711603,\n",
       "       1.37460343, 1.37115152, 1.36664098, 1.37776421, 1.37068191,\n",
       "       1.38013059, 1.36368806, 1.37033984, 1.37746367, 1.37324332,\n",
       "       1.37810189, 1.37454169, 1.37165396, 1.37467902, 1.38074284,\n",
       "       1.38501406, 1.38215009, 1.37101123, 1.3696212 , 1.38033818,\n",
       "       1.37068475, 1.3772233 , 1.37981606, 1.3828736 , 1.38440167,\n",
       "       1.37521361, 1.37410699, 1.37205835, 1.37556306, 1.36818371,\n",
       "       1.37687122, 1.36455665, 1.37982496, 1.3792308 , 1.37381428,\n",
       "       1.3728413 , 1.37989934, 1.37138604, 1.36817697, 1.37499359,\n",
       "       1.37646857, 1.37454475, 1.36958822, 1.37137499, 1.37230896,\n",
       "       1.37170969, 1.37089578, 1.37214325, 1.36963548, 1.38442545,\n",
       "       1.3797339 , 1.37623716, 1.36987535, 1.37846059, 1.38055327,\n",
       "       1.38064689, 1.37821613, 1.39110097, 1.37748776, 1.37581529,\n",
       "       1.37006247, 1.38094284, 1.36813161, 1.37279577, 1.37599578,\n",
       "       1.37071231, 1.37262178, 1.37247873, 1.38205443, 1.37629723,\n",
       "       1.37747265, 1.37280088, 1.38688112, 1.37956251, 1.37788592,\n",
       "       1.36817034, 1.37872444, 1.38235313, 1.38203163, 1.37420266,\n",
       "       1.38654199, 1.36834315, 1.37220558, 1.38077098, 1.37894947,\n",
       "       1.37921309, 1.37932561, 1.3750059 , 1.37031763, 1.38039403,\n",
       "       1.37136627, 1.37471339, 1.38566433, 1.37247534, 1.37629943,\n",
       "       1.3671816 , 1.38463699, 1.38057525, 1.38124445, 1.3824102 ,\n",
       "       1.36054409, 1.37594561, 1.3813625 , 1.37898127, 1.37343271,\n",
       "       1.38408858, 1.37380377, 1.37075993, 1.38617397, 1.37668299,\n",
       "       1.37052191, 1.37697342, 1.37947633, 1.37882526, 1.36910334,\n",
       "       1.37432485, 1.37205113, 1.38117352, 1.36346313, 1.37523319,\n",
       "       1.37702796, 1.38354686, 1.37226864, 1.37907589, 1.37513692,\n",
       "       1.37284924, 1.37643779, 1.37693947, 1.37486971, 1.37790261,\n",
       "       1.37369036, 1.38319885, 1.39111772, 1.37313769, 1.38957317,\n",
       "       1.37460197, 1.37885601, 1.36898685, 1.38166752, 1.37710585,\n",
       "       1.37880606, 1.37295407, 1.37381149, 1.37263099, 1.37162979,\n",
       "       1.37277277, 1.38507643, 1.37316231, 1.38185341, 1.38360451,\n",
       "       1.37951093, 1.37559682, 1.36218093, 1.37796301, 1.3730582 ,\n",
       "       1.372096  , 1.37869798, 1.39075182, 1.37635151, 1.36918652,\n",
       "       1.3698787 , 1.37812755, 1.37890821, 1.37142982, 1.37020409,\n",
       "       1.37143009, 1.37487747, 1.37118945, 1.3729995 , 1.37906728,\n",
       "       1.37913209, 1.37882077, 1.36463152, 1.37288927, 1.37251267,\n",
       "       1.35907868, 1.37266634, 1.37617222, 1.37535721, 1.375001  ,\n",
       "       1.39231055, 1.38008568, 1.3706397 , 1.37188782, 1.36536642,\n",
       "       1.37478787, 1.3718681 , 1.37693511, 1.37480734, 1.38082388,\n",
       "       1.37296739, 1.3649926 , 1.37023346, 1.3818839 , 1.36374401,\n",
       "       1.37330525, 1.3851948 , 1.37682678, 1.37044766, 1.37521905,\n",
       "       1.3765358 , 1.37637527, 1.37048695, 1.37511028, 1.37144931,\n",
       "       1.38127894, 1.38246565, 1.37566185, 1.36664941, 1.37270537,\n",
       "       1.38069363, 1.37148039, 1.36736805, 1.37689162, 1.37113042,\n",
       "       1.37810636, 1.37321274, 1.37545479, 1.37546634, 1.38113742,\n",
       "       1.37835718, 1.37604044, 1.37689798, 1.37689004, 1.37267934,\n",
       "       1.37473746, 1.37396348, 1.37884197, 1.36563235, 1.37163211,\n",
       "       1.37912081, 1.37413487, 1.3779107 , 1.38211477, 1.38502807,\n",
       "       1.38666354, 1.37497023, 1.37862721, 1.36996135, 1.3715338 ,\n",
       "       1.36187581, 1.37505937, 1.37785045, 1.38363406, 1.37719541,\n",
       "       1.36882756, 1.38264532, 1.37189872, 1.3651878 , 1.37999631,\n",
       "       1.3757965 , 1.38361696, 1.37515067, 1.3654112 , 1.38062093,\n",
       "       1.37973881, 1.37593358, 1.37577371, 1.37908538, 1.37359557,\n",
       "       1.37503627, 1.37425176, 1.37231049, 1.37328315, 1.37993415,\n",
       "       1.36722275, 1.38323944, 1.37284592, 1.37392172, 1.38247829,\n",
       "       1.36794611, 1.37840957, 1.3771066 , 1.36344281, 1.37385556,\n",
       "       1.37830877, 1.37761652, 1.37495705, 1.36867343, 1.38908889,\n",
       "       1.38010588, 1.38010727, 1.38380814, 1.37935103, 1.3767865 ,\n",
       "       1.36834068, 1.37206253, 1.38679897, 1.38367943, 1.36260094,\n",
       "       1.36506084, 1.37635853, 1.3806663 , 1.38284931, 1.37683179,\n",
       "       1.3739457 , 1.37627038, 1.37594367, 1.37497761, 1.36724667,\n",
       "       1.37032864, 1.37873722, 1.37864153, 1.37143025, 1.36918244,\n",
       "       1.37812751, 1.3779826 , 1.36343106, 1.37586857, 1.36811822,\n",
       "       1.38100686, 1.36688074, 1.3713889 , 1.37969706, 1.37713724,\n",
       "       1.3781333 , 1.38428482, 1.37154237, 1.37936631, 1.37700581,\n",
       "       1.37967991, 1.38292886, 1.37935673, 1.37791112, 1.37093496,\n",
       "       1.38222043, 1.36954519, 1.36751277, 1.38357703, 1.37388881,\n",
       "       1.36863286, 1.3697488 , 1.37103993, 1.37851019, 1.37617905,\n",
       "       1.37373588, 1.3765003 , 1.37323294, 1.37194652, 1.37842351,\n",
       "       1.3807992 , 1.37003603, 1.37755172, 1.36713389, 1.37409475,\n",
       "       1.37980713, 1.37380686, 1.38248407, 1.37678968, 1.37552274,\n",
       "       1.371243  , 1.37321751, 1.36727574, 1.37259341, 1.36780731,\n",
       "       1.3866042 , 1.37785743, 1.37175832, 1.36980782, 1.37095457,\n",
       "       1.37261272, 1.37300736, 1.3783064 , 1.36596971, 1.36892169,\n",
       "       1.37289552, 1.37234491, 1.37112802, 1.38362672, 1.37679758,\n",
       "       1.37451285, 1.36826607, 1.37036704, 1.3853451 , 1.37692089,\n",
       "       1.37351755, 1.37687607, 1.38393791, 1.37618666, 1.37908855,\n",
       "       1.36931842, 1.3781987 , 1.36394096, 1.37692613, 1.37974864,\n",
       "       1.37963415, 1.37105124, 1.37433895, 1.3670066 , 1.37080407,\n",
       "       1.37372353, 1.37846665, 1.37513885, 1.37827937, 1.37413939,\n",
       "       1.36729542, 1.37151756, 1.36693089, 1.37479997, 1.3740161 ,\n",
       "       1.37727384, 1.38158119, 1.37874491, 1.37740265, 1.38069135,\n",
       "       1.37304944, 1.37956233, 1.37582164, 1.37824069, 1.37983333,\n",
       "       1.37393944, 1.38356638, 1.36877998, 1.37655583, 1.37392677,\n",
       "       1.37605287, 1.3733866 , 1.36937725, 1.37622377, 1.37830137,\n",
       "       1.36765484, 1.37376769, 1.36909722, 1.39090642, 1.3722897 ,\n",
       "       1.37561155, 1.37689505, 1.37713645, 1.37728446, 1.37811218,\n",
       "       1.38056814, 1.37621711, 1.37211701, 1.37819709, 1.39155072,\n",
       "       1.36656879, 1.38032739, 1.37731786, 1.3745196 , 1.37906856,\n",
       "       1.37938506, 1.3838634 , 1.38487511, 1.37084382, 1.36796232,\n",
       "       1.38095486, 1.36907491, 1.37229386, 1.37756454, 1.37499241,\n",
       "       1.37632216, 1.37694661, 1.37980883, 1.38791972, 1.38312974])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean,var=scipy.stats.distributions.norm.fit(data)\n",
    "boundary_1=norm.ppf(0.33, loc=mean, scale=var)\n",
    "boundary_2=norm.ppf(0.66, loc=mean, scale=var)\n",
    "# boundary_3=norm.ppf(0.60, loc=mean, scale=var)\n",
    "# boundary_4=norm.ppf(0.60, loc=mean, scale=var)\n",
    "\n",
    "\n",
    "zeros=np.zeros(1000)\n",
    "\n",
    "y_zero=np.column_stack([data,zeros])\n",
    "for i in range(0,len(y_zero[:,-1])):\n",
    "    if y_zero[i,0]< boundary_1:\n",
    "        y_zero[i,-1]=0\n",
    "    elif boundary_1<y_zero[i,0]< boundary_2:\n",
    "        y_zero[i,-1]=1\n",
    "#     elif boundary_2<sigma_zero[i,3]< boundary_3:\n",
    "#         sigma_zero[i,-1]=2\n",
    "    else:\n",
    "        y_zero[i,-1]=2\n",
    "        \n",
    "y=y_zero[:,-1]\n",
    "\n",
    "# X_1=sigma_label[:,:4]\n",
    "# y_1=sigma_label[:,-1].astype(int)\n",
    "\n",
    "# # demonstrate data normalization with sklearn\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # create scaler\n",
    "# scaler = MinMaxScaler()\n",
    "# # fit and transform in one step\n",
    "# normalized = scaler.fit_transform(X_1)\n",
    "\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(normalized, y_1,  test_size=0.3, train_size=0.7, stratify=y_1,\n",
    "#                                                      random_state=1)\n",
    "# clf = MLPClassifier(random_state=1, max_iter=2000).fit(X_train, y_train)\n",
    "# clf.predict_proba(X_test[:1])\n",
    "\n",
    "\n",
    "# clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.loadtxt('beta_orientations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.343"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "kernel = 1.0 * RBF(1.0)\n",
    "gpc = GaussianProcessClassifier(kernel=kernel,\n",
    "        random_state=0).fit(x, y)\n",
    "gpc.score(x, y)\n",
    "\n",
    "# gpc.predict_proba(x[:2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.344 (0.018)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\t\n",
    "# evaluate a gaussian process classifier model on the dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "# define model\n",
    "model = GaussianProcessClassifier()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# summarize result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Accuracy: 0.343\n",
      "Best Config: {'kernel': 1**2 * WhiteKernel(noise_level=1)}\n",
      ">0.328 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      ">0.318 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      ">0.329 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      ">0.328 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      ">0.343 with: {'kernel': 1**2 * WhiteKernel(noise_level=1)}\n"
     ]
    }
   ],
   "source": [
    "# grid search kernel for gaussian process classifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel\n",
    "\n",
    "# define model\n",
    "model = GaussianProcessClassifier()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(), 1*DotProduct(), 1*Matern(),  1*RationalQuadratic(), 1*WhiteKernel()]\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(x, y)\n",
    "# summarize best\n",
    "print('Best Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Best Config: %s' % results.best_params_)\n",
    "# summarize all\n",
    "means = results.cv_results_['mean_test_score']\n",
    "params = results.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\">%.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3959737011614728"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.359078679909353"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3730363445283618"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.377932967798732"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3836753607440995"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data)-(np.max(data)-np.min(data))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 0., 1., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 2., 1.,\n",
       "       0., 2., 2., 2., 2., 1., 2., 2., 1., 2., 1., 0., 1., 0., 0., 2., 0.,\n",
       "       2., 0., 2., 1., 0., 1., 1., 1., 0., 1., 0., 2., 2., 2., 0., 0., 1.,\n",
       "       0., 2., 0., 0., 2., 0., 1., 2., 2., 2., 1., 2., 1., 2., 2., 1., 1.,\n",
       "       0., 1., 2., 0., 1., 0., 1., 1., 1., 1., 0., 2., 0., 0., 0., 1., 0.,\n",
       "       1., 2., 2., 0., 0., 1., 2., 1., 0., 0., 1., 0., 2., 0., 2., 2., 1.,\n",
       "       2., 2., 1., 2., 2., 0., 0., 1., 0., 2., 1., 0., 1., 0., 1., 1., 2.,\n",
       "       2., 0., 2., 1., 2., 0., 1., 2., 1., 2., 2., 2., 0., 1., 1., 0., 0.,\n",
       "       2., 2., 0., 2., 0., 2., 0., 2., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 2., 2., 1., 1., 1., 0., 0., 0., 2., 0., 2., 0.,\n",
       "       2., 0., 2., 0., 2., 1., 2., 2., 0., 2., 2., 0., 0., 0., 2., 2., 0.,\n",
       "       0., 0., 1., 2., 0., 0., 2., 2., 1., 1., 2., 1., 1., 0., 1., 2., 2.,\n",
       "       2., 2., 1., 2., 1., 0., 2., 2., 1., 2., 1., 2., 0., 2., 2., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 2., 1., 2., 2., 2., 2., 2., 2., 1., 0., 2.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 1., 0., 2., 1., 0., 2., 0., 0., 1., 1.,\n",
       "       0., 2., 2., 0., 1., 2., 2., 1., 2., 1., 0., 0., 2., 1., 2., 2., 0.,\n",
       "       0., 2., 1., 2., 1., 0., 0., 1., 1., 1., 2., 1., 0., 2., 1., 0., 0.,\n",
       "       2., 0., 1., 2., 0., 0., 2., 2., 1., 2., 0., 0., 2., 0., 0., 0., 2.,\n",
       "       2., 0., 0., 0., 2., 0., 0., 0., 0., 2., 0., 2., 1., 2., 1., 2., 1.,\n",
       "       2., 2., 0., 2., 0., 1., 1., 1., 1., 2., 0., 1., 2., 0., 2., 1., 1.,\n",
       "       0., 0., 2., 2., 0., 2., 1., 2., 1., 2., 0., 2., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 2., 1., 2., 1., 0., 0., 2., 0., 1., 1., 2., 0., 2., 2.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 2., 0., 2., 0., 1., 0., 1., 2., 1., 2.,\n",
       "       1., 1., 1., 2., 2., 2., 2., 1., 0., 1., 0., 0., 0., 2., 0., 0., 1.,\n",
       "       0., 1., 1., 2., 0., 2., 2., 1., 0., 0., 1., 0., 1., 2., 0., 2., 2.,\n",
       "       0., 2., 1., 1., 0., 1., 2., 1., 2., 0., 0., 0., 1., 1., 2., 2., 2.,\n",
       "       2., 1., 1., 2., 0., 1., 0., 0., 2., 0., 0., 2., 1., 2., 0., 2., 0.,\n",
       "       2., 2., 1., 2., 1., 2., 2., 1., 1., 0., 0., 1., 0., 0., 2., 2., 2.,\n",
       "       0., 1., 0., 2., 2., 0., 2., 2., 0., 2., 1., 2., 1., 0., 2., 1., 0.,\n",
       "       2., 2., 0., 2., 1., 1., 2., 0., 0., 0., 1., 2., 2., 0., 0., 0., 0.,\n",
       "       1., 0., 2., 0., 0., 1., 2., 1., 0., 0., 0., 1., 2., 2., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 2., 0., 1., 0., 2., 0., 2., 1., 0., 1., 2.,\n",
       "       0., 1., 0., 0., 1., 0., 2., 0., 0., 1., 1., 2., 1., 0., 1., 2., 2.,\n",
       "       2., 0., 0., 2., 0., 1., 2., 2., 2., 1., 1., 0., 1., 0., 1., 0., 2.,\n",
       "       2., 1., 0., 2., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       2., 1., 0., 2., 2., 2., 2., 2., 1., 1., 0., 2., 0., 0., 1., 0., 0.,\n",
       "       0., 2., 1., 1., 0., 2., 2., 1., 0., 2., 2., 2., 1., 2., 0., 0., 2.,\n",
       "       2., 2., 2., 1., 0., 2., 0., 1., 2., 0., 1., 0., 2., 2., 2., 2., 0.,\n",
       "       1., 2., 2., 1., 2., 1., 0., 2., 1., 0., 1., 2., 2., 0., 1., 0., 2.,\n",
       "       0., 1., 1., 2., 0., 2., 1., 0., 1., 1., 1., 1., 1., 2., 2., 1., 2.,\n",
       "       1., 2., 0., 2., 1., 2., 0., 1., 0., 0., 0., 2., 1., 2., 2., 2., 1.,\n",
       "       0., 2., 1., 0., 2., 2., 1., 0., 0., 2., 2., 0., 0., 0., 1., 0., 0.,\n",
       "       2., 2., 2., 0., 0., 0., 0., 0., 1., 1., 1., 2., 2., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 2., 0., 0., 0., 2., 0., 1., 2., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 2., 2., 1., 0., 0., 2., 0., 0., 1., 0., 2., 1., 1., 1., 2.,\n",
       "       2., 1., 1., 1., 0., 1., 1., 2., 0., 0., 2., 1., 1., 2., 2., 2., 1.,\n",
       "       2., 0., 0., 0., 1., 1., 2., 1., 0., 2., 0., 0., 2., 1., 2., 1., 0.,\n",
       "       2., 2., 1., 1., 2., 1., 1., 1., 0., 1., 2., 0., 2., 0., 1., 2., 0.,\n",
       "       2., 1., 0., 1., 2., 1., 1., 0., 2., 2., 2., 2., 2., 1., 0., 0., 2.,\n",
       "       2., 0., 0., 1., 2., 2., 1., 1., 1., 1., 1., 0., 0., 2., 2., 0., 0.,\n",
       "       2., 2., 0., 1., 0., 2., 0., 0., 2., 1., 2., 2., 0., 2., 1., 2., 2.,\n",
       "       2., 1., 0., 2., 0., 0., 2., 1., 0., 0., 0., 2., 1., 1., 1., 1., 0.,\n",
       "       2., 2., 0., 1., 0., 1., 2., 1., 2., 1., 1., 0., 1., 0., 0., 0., 2.,\n",
       "       1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 2., 1., 1., 0., 0.,\n",
       "       2., 1., 1., 1., 2., 1., 2., 0., 2., 0., 1., 2., 2., 0., 1., 0., 0.,\n",
       "       1., 2., 1., 2., 1., 0., 0., 0., 1., 1., 1., 2., 2., 1., 2., 1., 2.,\n",
       "       1., 2., 2., 1., 2., 0., 1., 1., 1., 1., 0., 1., 2., 0., 1., 0., 2.,\n",
       "       0., 1., 1., 1., 1., 2., 2., 1., 0., 2., 2., 0., 2., 1., 1., 2., 2.,\n",
       "       2., 2., 0., 0., 2., 0., 0., 1., 1., 1., 1., 2., 2., 2.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
